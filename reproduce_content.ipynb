{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9b6fbc",
   "metadata": {},
   "source": [
    "# Reproducibility Project Notebook for Readmission Prediction via Deep Contextual Embedding of Clinical Concepts\n",
    "\n",
    "- Data processing\n",
    "- Content model implementation\n",
    "- Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39807a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from util import *\n",
    "from common import full_eval\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20fd83",
   "metadata": {},
   "source": [
    "## Process EHR data\n",
    "\n",
    "Based on EHR data sorted by time, convert description test to numerical ids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38956524",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file = './data/S1_File.txt' # this is the original synthetic data file, we use sorted version instead\n",
    "input_file = './resource/s1_sorted.csv'\n",
    "vocab_file = './resource/vocab.txt'\n",
    "stop_file = './resource/stop.txt'\n",
    "vocab_pkl = './resource/vocab.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41afb3c2",
   "metadata": {},
   "source": [
    "### About Raw Data\n",
    "\n",
    "Synthetic data based on real EHR data. 3000 patients in total. No demographic information is included.\n",
    "\n",
    "- `PID` patient id\n",
    "- `DAY_ID` numerical date identifier with time difference preserved\n",
    "- `DX_GROUP_DESCRIPTION` diagnosis text descriptions\n",
    "- `SERVICE_LOCATION`\n",
    "- `OP_DATE` record posting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7023a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PID  DAY_ID                               DX_GROUP_DESCRIPTION  \\\n",
      "0    1   73888                                    ANGINA PECTORIS   \n",
      "1    1   73888  MONONEURITIS OF UPPER LIMB AND MONONEURITIS MU...   \n",
      "2    1   73888  SYMPTOMS INVOLVING RESPIRATORY SYSTEM AND OTHE...   \n",
      "\n",
      "  SERVICE_LOCATION  OP_DATE  \n",
      "0   DOCTORS OFFICE    74084  \n",
      "1   DOCTORS OFFICE    74084  \n",
      "2   DOCTORS OFFICE    74084  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(raw_file, sep='\\t', header=0)\n",
    "print(df[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44d53c",
   "metadata": {},
   "source": [
    "The data should be first sorted by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a0e1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data():\n",
    "    df = pd.read_csv(raw_file, sep='\\t', header=0)\n",
    "    sorted_df = df.sort_values(by=['PID', 'DAY_ID'], ascending=True).reset_index().drop(columns=[\"index\"])\n",
    "    sorted_df.to_csv(input_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dbd478",
   "metadata": {},
   "source": [
    "`dump_vocab` parse S1 data, collect DX_GROUP_DESCRIPTION vocabulary.\n",
    "\n",
    "Filter words with low occurrence (rare word), store high occurrence word in stop.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d281579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_vocab():\n",
    "    df = pd.read_csv(input_file, sep='\\t', header=0)\n",
    "\n",
    "    # .to_frame(): indexed by the groups, with a custom name\n",
    "    # .reset_index(): set the groups to be columns again\n",
    "    # after groupby, there are 1412 unique descriptions\n",
    "    hist = df.groupby('DX_GROUP_DESCRIPTION').size().to_frame('SIZE').reset_index()\n",
    "    print(hist[0:3])\n",
    "\n",
    "    # show some stats\n",
    "    hist_sort = hist.sort_values(by='SIZE', ascending=False)\n",
    "    print(hist_sort[0:3])\n",
    "    count = hist.groupby('SIZE').size().to_frame('COUNT').reset_index()\n",
    "    print(count)\n",
    "\n",
    "    # filter low occurrence descriptions, this leaves 490 unique descriptions with more than 100 occurrences\n",
    "    hist = hist[hist['SIZE'] > rare_word]\n",
    "    print(hist)\n",
    "\n",
    "    # dump\n",
    "    vocab = hist.sort_values(by='SIZE').reset_index()['DX_GROUP_DESCRIPTION']\n",
    "    vocab.index += 2  # reserve 1 to unk\n",
    "    vocab.to_csv(vocab_file, sep='\\t', header=False, index=True)\n",
    "\n",
    "    # there are 12 descriptions with more than 10000 occurrences.\n",
    "    hist[hist['SIZE'] > stop_word].reset_index()['DX_GROUP_DESCRIPTION'] \\\n",
    "        .to_csv(stop_file, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f1db34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab():\n",
    "    word_to_index = {}\n",
    "    with open(vocab_file, mode='r') as f:\n",
    "        line = f.readline()\n",
    "        while line != '':\n",
    "            tokens = line.strip().split('\\t')\n",
    "            word_to_index[tokens[1]] = int(tokens[0])\n",
    "            line = f.readline()\n",
    "    print('dict size: ' + str(len(word_to_index)))\n",
    "    save_pkl(vocab_pkl, {v: k for k, v in word_to_index.items()})\n",
    "    return word_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d6f8c",
   "metadata": {},
   "source": [
    "Events with label 'INPATIENT HOSPITAL' signals hospital admission.\n",
    "Group by patient and date then sorted by time for event sequence parsing.\n",
    "\n",
    "<img src=./doc/visit_sequence.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ed63d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events():\n",
    "    # extract event \"INPATIENT HOSPITAL\"\n",
    "    target_event = 'INPATIENT HOSPITAL'\n",
    "\n",
    "    df = pd.read_csv(input_file, sep='\\t', header=0)\n",
    "    events = df[df['SERVICE_LOCATION'] == target_event]\n",
    "\n",
    "    # 30742 pid-day_id pairs with inpatient hospital event\n",
    "    events = events.groupby(['PID', 'DAY_ID', 'SERVICE_LOCATION']).size().to_frame('COUNT').reset_index() \\\n",
    "        .sort_values(by=['PID', 'DAY_ID'], ascending=True) \\\n",
    "        .set_index('PID')\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130252b",
   "metadata": {},
   "source": [
    "`convert_format` group records in to patient-date 2d array, while converting description text to their numerical ids.\n",
    "Unknown description represented by 1.\n",
    "\n",
    "Tag sequence with positive readmission label if there are inpatient events within 30 days of the current visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7f97477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(events, pid, day_id):\n",
    "    return 1 if tag_logic(events, pid, day_id) else 0\n",
    "\n",
    "\n",
    "def tag_logic(events, pid, day_id):\n",
    "    try:\n",
    "        patient = events.loc[int(pid)]\n",
    "\n",
    "        # test whether have events within 30 days\n",
    "        if isinstance(patient, pd.Series):\n",
    "            return (int(day_id) <= patient.DAY_ID) & (patient.DAY_ID < int(day_id) + 30)\n",
    "\n",
    "        return patient.loc[(int(day_id) <= patient.DAY_ID) & (patient.DAY_ID < int(day_id) + 30)].shape[0] > 0\n",
    "    except KeyError:\n",
    "        # the label is not in the [index]\n",
    "        return False\n",
    "\n",
    "    \n",
    "def convert_format(word_to_index, events):\n",
    "    # order by PID, DAY_ID\n",
    "    with open(input_file, mode='r') as f:\n",
    "        # header\n",
    "        header = f.readline().strip().split('\\t')\n",
    "        print(header)\n",
    "        pos = {}\n",
    "        for key, value in enumerate(header):\n",
    "            pos[value] = key\n",
    "        print(pos)\n",
    "\n",
    "        docs = []  #\n",
    "        doc = []  # packs all events of the same patient\n",
    "        sent = []  # pack events in the same day\n",
    "        labels = []\n",
    "        label = []\n",
    "\n",
    "        # init\n",
    "        line = f.readline()\n",
    "        tokens = line.strip().split('\\t')\n",
    "        pid = tokens[pos['PID']]\n",
    "        day_id = tokens[pos['DAY_ID']]\n",
    "        label.append(tag(events, pid, day_id))\n",
    "\n",
    "        while line != '':\n",
    "            tokens = line.strip().split('\\t')\n",
    "            c_pid = tokens[pos['PID']]\n",
    "            c_day_id = tokens[pos['DAY_ID']]\n",
    "\n",
    "            # move to next patient\n",
    "            if c_pid != pid:\n",
    "                doc.append(sent)\n",
    "                docs.append(doc)\n",
    "                sent = []\n",
    "                doc = []\n",
    "                pid = c_pid\n",
    "                day_id = c_day_id\n",
    "                labels.append(label)\n",
    "                label = [tag(events, pid, day_id)]\n",
    "            else:\n",
    "                if c_day_id != day_id:\n",
    "                    doc.append(sent)\n",
    "                    sent = []\n",
    "                    day_id = c_day_id\n",
    "                    label.append(tag(events, pid, day_id))\n",
    "\n",
    "            word = tokens[pos['DX_GROUP_DESCRIPTION']]\n",
    "            try:\n",
    "                sent.append(word_to_index[word])\n",
    "            except KeyError:\n",
    "                sent.append(unknown)\n",
    "\n",
    "            line = f.readline()\n",
    "\n",
    "        # closure\n",
    "        doc.append(sent)\n",
    "        docs.append(doc)\n",
    "        labels.append(label)\n",
    "\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d264d",
   "metadata": {},
   "source": [
    "Then split sequence and labels into train, validation, test sets.\n",
    "\n",
    "Each patient would only belong to one set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fe38940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(docs, labels):\n",
    "    # train, validate, test\n",
    "    # X, Y,\n",
    "    # 3000 patients\n",
    "    print(len(docs))\n",
    "    print(len(labels))\n",
    "\n",
    "    save_pkl('./resource/X_train.pkl', docs[:2000])\n",
    "    save_pkl('./resource/Y_train.pkl', labels[:2000])\n",
    "    save_pkl('./resource/X_valid.pkl', docs[2000:2350])\n",
    "    save_pkl('./resource/Y_valid.pkl', labels[2000:2350])\n",
    "    save_pkl('./resource/X_test.pkl', docs[2350:])\n",
    "    save_pkl('./resource/Y_test.pkl', labels[2350:])\n",
    "    save_pkl('./resource/X_complete.pkl', docs)\n",
    "    save_pkl('./resource/Y_complete.pkl', labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e34ea",
   "metadata": {},
   "source": [
    "Data preprocessing main logic commented out to directly use saved intermediate results in `resource/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63323310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_data()\n",
    "# dump_vocab()\n",
    "# word_to_index = load_vocab()\n",
    "# events = extract_events()\n",
    "\n",
    "# docs, labels = convert_format(word_to_index, events)\n",
    "# split_data(docs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d3b2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] load resource/X_train.pkl\n",
      " [*] load resource/Y_train.pkl\n",
      " [*] load resource/X_valid.pkl\n",
      " [*] load resource/Y_valid.pkl\n",
      " [*] load resource/X_test.pkl\n",
      " [*] load resource/Y_test.pkl\n"
     ]
    }
   ],
   "source": [
    "doc_train = load_pkl(\"resource/X_train.pkl\")\n",
    "lb_train = load_pkl(\"resource/Y_train.pkl\")\n",
    "doc_val = load_pkl(\"resource/X_valid.pkl\")\n",
    "lb_val = load_pkl(\"resource/Y_valid.pkl\")\n",
    "doc_test = load_pkl(\"resource/X_test.pkl\")\n",
    "lb_test = load_pkl(\"resource/Y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd2e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_codes = 492"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83d6e32e",
   "metadata": {},
   "source": [
    "For content model, each visit is represented by a multi hot vector, with event code as active index positions.\n",
    "\n",
    "Each patient complete history is split into mutliple sequences, and each sequence is labelled separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "738cb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence_hot_code(docs, labels):\n",
    "    split_sequences = []\n",
    "    split_labels = []\n",
    "    idx_to_patient = []\n",
    "    for i in range(len(docs)):\n",
    "        patient_seq = docs[i]\n",
    "        patient_labels = labels[i]\n",
    "        for j in range(len(patient_seq)):\n",
    "            sub_seq = patient_seq[0:j+1]\n",
    "            seq_hc = []\n",
    "            for visit in sub_seq:\n",
    "                visit_hc = [0] * (num_codes-1)\n",
    "                for mcode in visit:\n",
    "                    visit_hc[mcode-1] = 1\n",
    "                seq_hc.append(visit_hc)\n",
    "            split_sequences.append(seq_hc)\n",
    "            split_labels.append(patient_labels[j])\n",
    "            idx_to_patient.append(i)\n",
    "    return split_sequences, split_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340b24df",
   "metadata": {},
   "source": [
    "Optional: persist split result to `./resource`. Take up less than 2GiB of disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7609d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train, labels_train = split_sequence_hot_code(doc_train, lb_train)\n",
    "seq_val, labels_val = split_sequence_hot_code(doc_val, lb_val)\n",
    "seq_test, labels_test = split_sequence_hot_code(doc_test, lb_test)\n",
    "\n",
    "# store multi hot encoded data\n",
    "save_pkl('./resource/X_train_mhc.pkl', seq_train)\n",
    "save_pkl('./resource/Y_train_mhc.pkl', labels_train)\n",
    "save_pkl('./resource/X_valid_mhc.pkl', seq_val)\n",
    "save_pkl('./resource/Y_valid_mhc.pkl', labels_val)\n",
    "save_pkl('./resource/X_test_mhc.pkl', seq_test)\n",
    "save_pkl('./resource/Y_test_mhc.pkl', labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaac6d4",
   "metadata": {},
   "source": [
    "## Prepare data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b08d0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] load ./resource/X_train_mhc.pkl\n",
      " [*] load ./resource/Y_train_mhc.pkl\n",
      " [*] load ./resource/X_valid_mhc.pkl\n",
      " [*] load ./resource/Y_valid_mhc.pkl\n",
      " [*] load ./resource/X_test_mhc.pkl\n",
      " [*] load ./resource/Y_test_mhc.pkl\n"
     ]
    }
   ],
   "source": [
    "seq_train = load_pkl('./resource/X_train_mhc.pkl')\n",
    "labels_train = load_pkl('./resource/Y_train_mhc.pkl')\n",
    "seq_val = load_pkl('./resource/X_valid_mhc.pkl')\n",
    "labels_val = load_pkl('./resource/Y_valid_mhc.pkl')\n",
    "seq_test = load_pkl('./resource/X_test_mhc.pkl')\n",
    "labels_test = load_pkl('./resource/Y_test_mhc.pkl')\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, docs, labels):\n",
    "        self.x = docs\n",
    "        self.y = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "\n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patiens, max # visits, largest diagnosis code) of type torch.float, multi-host encoding of diagnosis code within each visit\n",
    "        masks: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.bool\n",
    "        rev_x: same as x but in reversed time.\n",
    "        rev_masks: same as mask but in reversed time.\n",
    "        y: a tensor of shape (# patiens) of type torch.float\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "\n",
    "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.float)\n",
    "    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.float)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            masks[i_patient][j_visit][:len(visit)] = True\n",
    "            x[i_patient][j_visit][:len(visit)] = torch.tensor(visit).type(torch.float)\n",
    "            rev_masks[i_patient][len(patient) - 1 - j_visit][:len(visit)] = True\n",
    "            rev_x[i_patient][len(patient) - 1 - j_visit][:len(visit)] = torch.tensor(visit).type(torch.float)\n",
    "\n",
    "    return x, masks, rev_x, rev_masks, y\n",
    "\n",
    "\n",
    "\n",
    "dataset_train = CustomDataset(seq_train, labels_train)\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "dataset_val = CustomDataset(seq_val, labels_val)\n",
    "val_loader = DataLoader(dataset_val, batch_size=16, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "dataset_test = CustomDataset(seq_test, labels_test)\n",
    "test_loader = DataLoader(dataset_test, batch_size=16, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d61ba1",
   "metadata": {},
   "source": [
    "After data processing with mhc version successfully stored, we could use utility function to directly init data loaders in the future\n",
    "\n",
    "- other models except rnn would require unique collate functions and loaders, import corresponding function from respective model script\n",
    "\n",
    "\n",
    "| model     | substitute functions                                   | batch size |\n",
    "|-----------|--------------------------------------------------------|------------|\n",
    "| CONTENT   | -                                                      | 16         |\n",
    "| RETAIN    | `load_seq`, `collate_fn`, `train`, `eval`, `full_eval` | 32         |\n",
    "| GRU       | -                                                      | 16         |\n",
    "| SimpAttn  | `collate_fn`, `train`, `eval`, `full_eval`             | 16         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59e8da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] load ./resource/X_train_mhc.pkl\n",
      " [*] load ./resource/Y_train_mhc.pkl\n",
      " [*] load ./resource/X_valid_mhc.pkl\n",
      " [*] load ./resource/Y_valid_mhc.pkl\n",
      " [*] load ./resource/X_test_mhc.pkl\n",
      " [*] load ./resource/Y_test_mhc.pkl\n"
     ]
    }
   ],
   "source": [
    "from data import load_seq, load_mhc\n",
    "from common import data_prepare, collate_fn\n",
    "\n",
    "train_loader, val_loader, test_loader = data_prepare(load_mhc, 16, collate_fn)\n",
    "\n",
    "## retain would use unique loaders\n",
    "# from retain import collate_fn\n",
    "# data_prepare(load_seq, 32, collate_fn)\n",
    "\n",
    "## simple attention would use\n",
    "# from attn import collate_fn\n",
    "# data_prepare(load_mhc, 16, collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522914de",
   "metadata": {},
   "source": [
    "# CONTENT model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39da1e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=./doc/content_model_illustration.png>\n",
    "\n",
    "First implement the recognition network (lower portion of the illustration above), which use MLP to produce distribution parameters for patient context generation.\n",
    "\n",
    "- The MLP produce $log(\\sigma)$ vector and $\\mu$ vector\n",
    "- Then the topic vector would be generated from distribution $N(\\mu, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c81cbf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognition(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=num_codes-1, hidden_dim=200, topic_dim=50):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Define the recognition MLP that generates topic vector theta;\n",
    "\n",
    "        Arguments:\n",
    "            input_dim: generator does not take embeddings, directly put input dimension here\n",
    "        \"\"\"\n",
    "\n",
    "        self.a_att = nn.Linear(input_dim, hidden_dim)\n",
    "        self.b_att = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.u_ln = nn.Linear(hidden_dim, topic_dim)\n",
    "        self.sigma_ln = nn.Linear(hidden_dim, topic_dim)\n",
    "\n",
    "        self.hidden = hidden_dim\n",
    "\n",
    "    def forward(self, x, masks):\n",
    "        \"\"\"\n",
    "\n",
    "        Arguments:\n",
    "            x: the multi hot encoded visits (batch_size, # visits, # total diagnosis codes)\n",
    "            masks: the padding masks of shape (batch_size, # visits, # total diagnosis codes)\n",
    "\n",
    "        Outputs:\n",
    "            gen: generated value from learned distribution\n",
    "        \"\"\"\n",
    "        # MLP to obtain mean and log_sigma values\n",
    "        x = torch.relu(self.a_att(x))  # (batch, visit, input) -> (batch, visit, hidden)\n",
    "        x = torch.relu(self.b_att(x))\n",
    "        lu = self.u_ln(x)  # -> (batch, visit, n_topic)\n",
    "        ls = self.sigma_ln(x)  # -> (batch, visit, n_topic)\n",
    "        visit_masks = torch.sum(masks, dim=-1).type(torch.bool)  # (batch, visit)\n",
    "        # calculate mean with mask\n",
    "        # (batch, n_topic) / (batch, 1)\n",
    "        mean_u = torch.sum(lu * visit_masks.unsqueeze(-1), dim=1) / torch.sum(visit_masks, dim=-1).unsqueeze(-1)\n",
    "        mean_log_sigma = torch.sum(ls * visit_masks.unsqueeze(-1), dim=1) / torch.sum(visit_masks, dim=-1).unsqueeze(-1)\n",
    "        # generate from learned distribution\n",
    "        gen = torch.randn(mean_u.shape) * torch.exp(mean_log_sigma) + mean_u  # (batch, n_topic)\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf21e9",
   "metadata": {},
   "source": [
    "Utility function to obtain GRU output at last valid visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9505c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_visit(hidden_states, masks):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        hidden_states: the hidden states of each visit of shape (batch_size, # visits, embedding_dim)\n",
    "        masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "    Outputs:\n",
    "        last_hidden_state: the hidden state for the last true visit of shape (batch_size, embedding_dim)\n",
    "\n",
    "    First convert the mask to a vector of shape (batch_size,) containing the true visit length;\n",
    "          and then use this length vector as index to select the last visit.\n",
    "    \"\"\"\n",
    "\n",
    "    idx = torch.sum(torch.sum(masks, -1) > 0, -1)\n",
    "    # pass two list in index [], so that each row would select different index according to idx.\n",
    "    return hidden_states[range(hidden_states.shape[0]), idx - 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e628c12d",
   "metadata": {},
   "source": [
    "Then the complete content structure, include the upper GRU network.\n",
    "\n",
    "The output from Recognition and GRU network are stiched together by matrix Q and B\n",
    "\n",
    "$$ Q^T * H + B^T * \\theta = Logits $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5580d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Content(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Define the CONTENT network that contains recognition and GRU modules;\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=num_codes-1, embedding_dim=100, hidden_dim=200, topic_dim=50):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            input_dim: generator does not take embeddings, directly put input dimension here\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc_embedding = nn.Linear(in_features=input_dim, out_features=embedding_dim)\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.recognition = Recognition(input_dim=input_dim, hidden_dim=hidden_dim, topic_dim=topic_dim)\n",
    "        self.fc_q = nn.Linear(hidden_dim, 1)\n",
    "        self.fc_b = nn.Linear(topic_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, masks):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: the multi hot encoded visits (batch_size, # visits, # total diagnosis codes)\n",
    "            masks: the padding masks of shape (batch_size, # visits, # total diagnosis codes)\n",
    "        \"\"\"\n",
    "        # x = x.type(dtype=torch.float)\n",
    "        x_embed = self.fc_embedding(x)\n",
    "        output, _ = self.rnn(x_embed)\n",
    "        final_visit_h = get_last_visit(output, masks)  # (batch_size, hidden_dim)\n",
    "        topics = self.recognition(x, masks)  # (batch_size, n_topic)\n",
    "        score = self.fc_q(final_visit_h) + self.fc_b(topics)  # (batch_size, 1)\n",
    "        return self.sigmoid(score).squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c02bf7",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "333e4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctn = Content(input_dim=num_codes-1)  # total vocab 491\n",
    "\n",
    "# load the loss function\n",
    "criterion = nn.BCELoss()\n",
    "# load the optimizer\n",
    "optimizer = torch.optim.Adam(ctn.parameters(), lr=0.00002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9df3a",
   "metadata": {},
   "source": [
    "Model summary and parameter count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f68941a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Content(\n",
       "  (fc_embedding): Linear(in_features=491, out_features=100, bias=True)\n",
       "  (rnn): GRU(100, 200, batch_first=True)\n",
       "  (recognition): Recognition(\n",
       "    (a_att): Linear(in_features=491, out_features=200, bias=True)\n",
       "    (b_att): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (u_ln): Linear(in_features=200, out_features=50, bias=True)\n",
       "    (sigma_ln): Linear(in_features=200, out_features=50, bias=True)\n",
       "  )\n",
       "  (fc_q): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (fc_b): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa36435c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389352"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in ctn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ff1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "\n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        train_loader: training dataloder\n",
    "        val_loader: validation dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, masks, rev_x, rev_masks, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x, masks)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch + 1, train_loss))\n",
    "        p, r, f, roc_auc = eval(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.4f}, r:{:.4f}, f: {:.4f}, roc_auc: {:.4f}'.format(epoch + 1, p, r, f,\n",
    "                                                                                               roc_auc))\n",
    "    return round(roc_auc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924ab6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "\n",
    "    Arguments:\n",
    "        model: the model\n",
    "        val_loader: validation dataloader\n",
    "\n",
    "    Outputs:\n",
    "        precision: overall precision score\n",
    "        recall: overall recall score\n",
    "        f1: overall f1 score\n",
    "        roc_auc: overall roc_auc score\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, masks, rev_x, rev_masks, y in val_loader:\n",
    "        y_logit = model(x, masks)\n",
    "        y_hat = torch.where(y_logit > 0.5, 1, 0)\n",
    "        y_score = torch.cat((y_score, y_logit.detach().to('cpu')), dim=0)\n",
    "        y_pred = torch.cat((y_pred, y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    return p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa031886",
   "metadata": {},
   "source": [
    "## Training and evaluation with test data\n",
    "\n",
    "Each epoch would take around 40 minutes with CPU training.\n",
    "\n",
    "Best result is obtained after 4 epochs.\n",
    "\n",
    "PR-AUC and ROC-AUC are the most significant metric. The printed F score as a reference, is based on threshold value 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 4\n",
    "print(time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "train(ctn, train_loader, val_loader, n_epochs)\n",
    "print(time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "\n",
    "# store model state dict\n",
    "torch.save(ctn.state_dict(), \"models/content_notebook.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2075fbcf",
   "metadata": {},
   "source": [
    "Test should report a ROC-AUC over 0.8 and PR-AUC over 0.67, which outperforms the retain model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77454977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test p: 0.7715, r:0.4524, f: 0.5704, roc_auc: 0.8090, pr_auc: 0.6753\n"
     ]
    }
   ],
   "source": [
    "# reload and evaluation\n",
    "\n",
    "model = Content(input_dim=num_codes - 1)\n",
    "model.load_state_dict(torch.load(\"models/content_opt.pth\")) # default to load optimal state dict\n",
    "p, r, f, roc_auc, pr_auc = full_eval(model, test_loader)\n",
    "print('Test p: {:.4f}, r:{:.4f}, f: {:.4f}, roc_auc: {:.4f}, pr_auc: {:.4f}'.format(p, r, f, roc_auc, pr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c3b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
